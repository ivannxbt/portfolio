---
title: "Pipelines de calidad de datos con Azure ML"
date: "2024-09-15"
summary: "Cómo combino Azure ML, Fabric y embeddings semánticos para asegurar datasets confiables antes de alimentar copilotos."
tags:
  - Azure ML
  - Calidad de datos
  - Pipelines
---

## Contexto
La mayoría de los "errores de IA" que reviso son fallas de calidad de datos. En stacks centrados en Azure ya existen Lakehouses de Fabric, Synapse y pipelines de ML. Podemos aprovechar esa infraestructura para puntuar corpora antes de que los LLMs los usen.

## Blueprint del pipeline
- **Ingesta** — Data Factory orientado a eventos normaliza archivos de SharePoint, SQL y SAP.
- **Perfilado** — Notebooks de Fabric ejecutan suites de Great Expectations más detección de duplicados con embeddings (modelos Cohere vía endpoints de Azure ML).
- **Gobernanza** — El metadata viaja a Purview; los lotes fallidos disparan alertas en Teams con playbooks de remediación.
- **Enriquecimiento** — Registros limpios quedan en tablas Delta con versionado para que los pipelines RAG puedan viajar en el tiempo ante regresiones.

## Métricas clave
1. Cobertura de datasets dorados por idioma.
2. Deriva entre clusters de embeddings offline y online.
3. Tiempo de detección de incidentes (objetivo: <15 minutos desde la ingesta).

## Aprendizajes
Trata Azure ML como la capa de decisiones, no solo entrenamiento. Cuando deduplicación y validación viven junto al registry, los bucles entre MLOps e ingenieros de conocimiento finalmente se alinean.
